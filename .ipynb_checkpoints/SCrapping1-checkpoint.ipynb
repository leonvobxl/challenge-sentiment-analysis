{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf72134",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00db29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff3553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da949556",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def username_tweets_to_csv(username,count):\n",
    "    try:      \n",
    "        # Creation of query method using parameters\n",
    "        tweets = tweepy.Cursor(api.user_timeline,id=username).items(count)\n",
    "\n",
    "        # Pulling information from tweets iterable object\n",
    "        tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    "\n",
    "        # Creation of dataframe from tweets list\n",
    "        # Add or remove columns as you remove tweet information\n",
    "        tweets_df = pd.DataFrame(tweets_list,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "        # Converting dataframe to CSV \n",
    "        tweets_df.to_csv('{}-tweets.csv'.format(username), sep=',', index = False)\n",
    "\n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ee96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input username to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "username = 'netflix'\n",
    "count = 1000\n",
    "\n",
    "# Calling function to turn username's past X amount of tweets into a CSV file\n",
    "username_tweets_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d806cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# Twitter API credentials\n",
    "consumer_key = '3OFay9dKMhwmvC8VmNPzssRii'\n",
    "consumer_secret = '2RU7kOQApou51r3nHRb3RRIHmLmfpUE6WplTnt5S6onjqusliq'\n",
    "access_token = '805517251382222848-Ck3xmv7TaCpaWHMARNrmU5HFyq7xKSB'\n",
    "access_token_secret = 'nk520oLJ6X63VP3Zn4g20F2yT2Y7eq9bARiW54kgGUA8P'\n",
    "\n",
    "\n",
    "# Authentication\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit = True)#, wait_on_rate_limit_notify=True)\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec971a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(username, key_word, nr_of_tweets):\n",
    "\n",
    "    twitter_users = []\n",
    "    tweet_time = []\n",
    "    tweet_string = [] \n",
    "    for tweet in tweepy.Cursor(api.search_tweets, api.user_timeline, q = key_word, id = username, count=1000).items(nr_of_tweets):\n",
    "            if (not tweet.retweeted) and ('RT @' not in tweet.text):\n",
    "                if tweet.lang == \"en\":\n",
    "                    twitter_users.append(tweet.user.name)\n",
    "                    tweet_time.append(tweet.created_at)\n",
    "                    tweet_string.append(tweet.text)\n",
    "                    #print([tweet.user.name,tweet.created_at,tweet.text])\n",
    "    df = pd.DataFrame({'name':twitter_users, 'time': tweet_time, 'tweet': tweet_string})\n",
    "    \n",
    "    return df \n",
    "get_related_tweets('netflix', 'queengambit', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ab662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(key_word, nr_of_tweets):\n",
    "\n",
    "    twitter_users = []\n",
    "    tweet_time = []\n",
    "    tweet_string = [] \n",
    "    for tweet in tweepy.Cursor(api.search_tweets, q= key_word, count=200).items(nr_of_tweets):\n",
    "        if tweet.lang == \"en\":\n",
    "            twitter_users.append(tweet.user.name)\n",
    "            tweet_time.append(tweet.created_at)\n",
    "            tweet_string.append(tweet.text)\n",
    "            #print([tweet.user.name,tweet.created_at,tweet.text])\n",
    "    df = pd.DataFrame({'name':twitter_users, 'time': tweet_time, 'tweet': tweet_string})\n",
    "    \n",
    "    return df \n",
    "\n",
    "get_related_tweets('queengambit', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeteo=[]\n",
    "likes=[]\n",
    "time = []\n",
    "for tuit in tweepy.Cursor(api.user_timeline,screen_name='Netflix').items(3100):\n",
    "    time.append(tuit.created_at)\n",
    "    likes.append(tuit.favorite_count)\n",
    "    tweeteo.append(tuit.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def clean_tweets(lst):\n",
    "    # remove twitter Return handles (RT @xxx:)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"RT @[\\w]*:\")\n",
    "    # remove twitter handles (@xxx)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"@[\\w]*\")\n",
    "    # remove URL links (httpxxx)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"https?://[A-Za-z0-9./]*\")\n",
    "    # remove special characters, numbers, punctuations (except for #)\n",
    "    lst = np.core.defchararray.replace(lst, \"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twist = clean_tweets(tweeteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'tweeteo':twist,'likes': likes, 'time': time}, columns = ['tweeteo','likes','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63667374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('netflix_twist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'squidgame'  #sweetgirl, #theguilty, #maid, #thechestnutman\n",
    "max_tweets = 1000\n",
    "lang = 'en'\n",
    "\n",
    " \n",
    "# Creation of query method using parameters\n",
    "twt_text = []\n",
    "twt_created = []\n",
    "twt_username = []\n",
    "twt_screenname = []\n",
    "twt_location = []\n",
    "\n",
    "for twt in tweepy.Cursor(api.search_tweets,q=text_query, lang = lang).items(max_tweets):\n",
    "    twt_text.append(twt.text)\n",
    "    twt_created.append(twt.created_at)\n",
    "    twt_username.append(twt.user.name)\n",
    "    twt_screenname.append(twt.user.screen_name)\n",
    "    twt_location.append(twt.user.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba26886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf098aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_text = clean_tweets(twt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03234afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'twist':twt_text,\n",
    "                    'created_at': twt_created, \n",
    "                    'username': twt_username,\n",
    "                    'screenname':twt_screenname,\n",
    "                    'location': twt_location}, columns = ['twist','created_at','username','screenname','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45414b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_by_cursor(text_query: str, max_tweets: int, lang: str):\n",
    " \n",
    "    # Creation of query method using parameters\n",
    "    twt_text = []\n",
    "    twt_created = []\n",
    "    twt_username = []\n",
    "    twt_screenname = []\n",
    "    twt_location = []\n",
    "\n",
    "    for twt in tweepy.Cursor(api.search_tweets,q=text_query, lang = lang).items(max_tweets):\n",
    "        if twt.user.screen_name == 'netflix':\n",
    "            twt_text.append(twt.text)\n",
    "            twt_created.append(twt.created_at)\n",
    "            twt_username.append(twt.user.name)\n",
    "            #twt_screenname.append(twt.user.screen_name)\n",
    "            twt_location.append(twt.user.location)\n",
    "    return twt_text, twt_created, twt_username, twt_screenname, twt_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f3b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_queengambit = scrape_by_cursor('#Queengambit', 100, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_sweetgirl = scrape_by_cursor('#sweetgirl', 3000, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5e0997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twt_maid = scrape_by_cursor('#maid', 100, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2772003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_squidgame = scrape_by_cursor('#squidgame', 100, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ce55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_thechestnutman = scrape_by_cursor('#thechestnutman', 3000, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_theguilty = scrape_by_cursor('#theguilty', 3000, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "054917be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twt_squidgame[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twt_sweetgirl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432cc628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twt_queengambit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_queengambit_text = clean_tweets(twt_queengambit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "twt_queengambit_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75993a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = (pd.DataFrame(tweets_df, columns = [\"mentions\"])).to_csv(csvfile2, index = False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c55f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_date = datetime.datetime(2021, 8, 12, 12, 00, 00)\n",
    "end_date = datetime.datetime(2021, 10, 12, 13, 00, 00)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.user_timeline, screen_name=\"@netflix\", since=start_date, until=end_date).items():\n",
    "    print(\"ID TWEET: \" + str(tweet.id)+str(tweet.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
